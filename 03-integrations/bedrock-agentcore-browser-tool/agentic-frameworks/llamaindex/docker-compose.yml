# Docker Compose configuration for llamaindex-agentcore-browser-integration
# Supports development, testing, and local production environments

version: '3.8'

services:
  # Main application service
  llamaindex-agentcore:
    build:
      context: .
      dockerfile: Dockerfile
      target: ${BUILD_TARGET:-production}
      args:
        BUILD_ENV: ${ENVIRONMENT:-production}
    image: llamaindex-agentcore-integration:${VERSION:-latest}
    container_name: llamaindex-agentcore-${ENVIRONMENT:-prod}
    restart: unless-stopped
    environment:
      - LLAMAINDEX_AGENTCORE_ENV=${ENVIRONMENT:-production}
      - AWS_DEFAULT_REGION=${AWS_REGION:-us-east-1}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_SESSION_TOKEN=${AWS_SESSION_TOKEN}
      - AGENTCORE_BROWSER_ENDPOINT=${AGENTCORE_BROWSER_ENDPOINT}
    volumes:
      - ./config:/app/config:ro
      - ./logs:/app/logs
      - ./data:/app/data
    ports:
      - "${APP_PORT:-8000}:8000"
    healthcheck:
      test: ["CMD", "python", "-c", "import llamaindex_agentcore_integration; print('OK')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - llamaindex-network
    depends_on:
      - redis
      - prometheus

  # Redis for caching and session storage
  redis:
    image: redis:7-alpine
    container_name: llamaindex-redis-${ENVIRONMENT:-prod}
    restart: unless-stopped
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - llamaindex-network

  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    container_name: llamaindex-prometheus-${ENVIRONMENT:-prod}
    restart: unless-stopped
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=15d'
      - '--web.enable-lifecycle'
    networks:
      - llamaindex-network

  # Grafana for monitoring dashboards
  grafana:
    image: grafana/grafana:latest
    container_name: llamaindex-grafana-${ENVIRONMENT:-prod}
    restart: unless-stopped
    ports:
      - "${GRAFANA_PORT:-3000}:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    networks:
      - llamaindex-network
    depends_on:
      - prometheus

  # Development service with hot reload
  llamaindex-dev:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
    image: llamaindex-agentcore-integration:dev
    container_name: llamaindex-agentcore-dev
    environment:
      - LLAMAINDEX_AGENTCORE_ENV=development
      - AWS_DEFAULT_REGION=${AWS_REGION:-us-east-1}
      - AWS_PROFILE=${AWS_PROFILE:-default}
    volumes:
      - .:/app
      - ./config:/app/config
      - ./logs:/app/logs
      - dev-cache:/app/.cache
    ports:
      - "8001:8000"
      - "8888:8888"  # Jupyter notebook
    networks:
      - llamaindex-network
    profiles:
      - development

  # Testing service
  llamaindex-test:
    build:
      context: .
      dockerfile: Dockerfile
      target: testing
    image: llamaindex-agentcore-integration:test
    container_name: llamaindex-agentcore-test
    environment:
      - LLAMAINDEX_AGENTCORE_ENV=testing
    volumes:
      - .:/app
      - test-results:/app/test-results
    networks:
      - llamaindex-network
    profiles:
      - testing

  # Nginx reverse proxy for production
  nginx:
    image: nginx:alpine
    container_name: llamaindex-nginx-${ENVIRONMENT:-prod}
    restart: unless-stopped
    ports:
      - "${NGINX_PORT:-80}:80"
      - "${NGINX_SSL_PORT:-443}:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - nginx-logs:/var/log/nginx
    networks:
      - llamaindex-network
    depends_on:
      - llamaindex-agentcore
    profiles:
      - production

volumes:
  redis-data:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  dev-cache:
    driver: local
  test-results:
    driver: local
  nginx-logs:
    driver: local

networks:
  llamaindex-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16