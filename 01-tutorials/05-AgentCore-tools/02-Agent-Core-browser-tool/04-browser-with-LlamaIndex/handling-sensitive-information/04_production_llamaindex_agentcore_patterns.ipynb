{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production LlamaIndex Patterns with AgentCore Browser Tool\n",
    "\n",
    "This notebook demonstrates production-ready patterns for deploying LlamaIndex with Amazon Bedrock AgentCore Browser Tool, focusing on:\n",
    "\n",
    "- **Scalable Architecture**: Session pooling, resource management, auto-scaling\n",
    "- **Monitoring & Observability**: Built-in AgentCore monitoring for sensitive operations\n",
    "- **Error Handling & Recovery**: Robust patterns protecting sensitive data\n",
    "- **Compliance & Audit Logging**: Enterprise-grade logging and compliance\n",
    "\n",
    "## Prerequisites\n",
    "- AWS credentials configured\n",
    "- Completed previous notebooks in this series\n",
    "- Understanding of production deployment patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import logging\n",
    "import time\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Any\n",
    "from dataclasses import dataclass, asdict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from contextlib import asynccontextmanager\n",
    "\n",
    "# LlamaIndex imports\n",
    "from llama_index.core import VectorStoreIndex, Document, Settings\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.llms.bedrock import Bedrock\n",
    "from llama_index.embeddings.bedrock import BedrockEmbedding\n",
    "\n",
    "# AgentCore Browser Tool\n",
    "from bedrock_agentcore.tools.browser_client import BrowserSession\n",
    "from bedrock_agentcore.tools.browser_client.browser_session import BrowserSessionConfig\n",
    "\n",
    "# Production utilities\n",
    "from examples.secure_rag_pipeline import SecureRAGPipeline\n",
    "from examples.agentcore_browser_loader import AgentCoreBrowserLoader\n",
    "from examples.sensitive_data_handler import SensitiveDataHandler\n",
    "\n",
    "# Configure production logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('production_llamaindex_agentcore.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"✅ Production dependencies loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Production Configuration & Session Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ProductionConfig:\n",
    "    \"\"\"Production configuration for LlamaIndex-AgentCore integration.\"\"\"\n",
    "    environment: str = \"production\"\n",
    "    region: str = \"us-east-1\"\n",
    "    max_concurrent_sessions: int = 10\n",
    "    session_timeout_minutes: int = 30\n",
    "    enable_audit_logging: bool = True\n",
    "    enable_pii_detection: bool = True\n",
    "    enable_metrics: bool = True\n",
    "    max_retries: int = 3\n",
    "    chunk_size: int = 1024\n",
    "    max_tokens: int = 4096\n",
    "\n",
    "class ProductionSessionPool:\n",
    "    \"\"\"Production session pool with monitoring and auto-cleanup.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ProductionConfig):\n",
    "        self.config = config\n",
    "        self.active_sessions: Dict[str, Dict] = {}\n",
    "        self.metrics = {\n",
    "            'total_created': 0,\n",
    "            'current_active': 0,\n",
    "            'peak_concurrent': 0\n",
    "        }\n",
    "    \n",
    "    async def get_session(self, session_id: Optional[str] = None) -> BrowserSession:\n",
    "        \"\"\"Get or create monitored browser session.\"\"\"\n",
    "        if session_id and session_id in self.active_sessions:\n",
    "            session_info = self.active_sessions[session_id]\n",
    "            if self._is_session_valid(session_info):\n",
    "                logger.info(f\"Reusing session: {session_id}\")\n",
    "                return session_info['session']\n",
    "            else:\n",
    "                await self._cleanup_session(session_id)\n",
    "        \n",
    "        # Check session limits\n",
    "        if len(self.active_sessions) >= self.config.max_concurrent_sessions:\n",
    "            await self._cleanup_oldest_session()\n",
    "        \n",
    "        # Create new session\n",
    "        session_id = session_id or str(uuid.uuid4())\n",
    "        session = await self._create_monitored_session(session_id)\n",
    "        \n",
    "        # Update metrics\n",
    "        self.metrics['total_created'] += 1\n",
    "        self.metrics['current_active'] = len(self.active_sessions)\n",
    "        self.metrics['peak_concurrent'] = max(\n",
    "            self.metrics['peak_concurrent'],\n",
    "            self.metrics['current_active']\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Created session: {session_id}\")\n",
    "        return session\n",
    "    \n",
    "    async def _create_monitored_session(self, session_id: str) -> BrowserSession:\n",
    "        \"\"\"Create session with production monitoring.\"\"\"\n",
    "        session_config = BrowserSessionConfig(\n",
    "            region=self.config.region,\n",
    "            enable_observability=True,\n",
    "            enable_audit_logging=self.config.enable_audit_logging,\n",
    "            session_timeout=self.config.session_timeout_minutes * 60\n",
    "        )\n",
    "        \n",
    "        session = BrowserSession(config=session_config)\n",
    "        await session.start()\n",
    "        \n",
    "        self.active_sessions[session_id] = {\n",
    "            'session': session,\n",
    "            'created_at': datetime.utcnow(),\n",
    "            'last_used': datetime.utcnow(),\n",
    "            'operation_count': 0\n",
    "        }\n",
    "        \n",
    "        return session\n",
    "    \n",
    "    def _is_session_valid(self, session_info: Dict) -> bool:\n",
    "        \"\"\"Check session validity.\"\"\"\n",
    "        timeout = timedelta(minutes=self.config.session_timeout_minutes)\n",
    "        return datetime.utcnow() - session_info['last_used'] < timeout\n",
    "    \n",
    "    async def _cleanup_session(self, session_id: str):\n",
    "        \"\"\"Clean up specific session.\"\"\"\n",
    "        if session_id in self.active_sessions:\n",
    "            session_info = self.active_sessions[session_id]\n",
    "            try:\n",
    "                await session_info['session'].close()\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error closing session {session_id}: {e}\")\n",
    "            \n",
    "            del self.active_sessions[session_id]\n",
    "            self.metrics['current_active'] = len(self.active_sessions)\n",
    "            logger.info(f\"Cleaned up session: {session_id}\")\n",
    "    \n",
    "    async def _cleanup_oldest_session(self):\n",
    "        \"\"\"Clean up oldest session.\"\"\"\n",
    "        if not self.active_sessions:\n",
    "            return\n",
    "        \n",
    "        oldest_id = min(\n",
    "            self.active_sessions.keys(),\n",
    "            key=lambda x: self.active_sessions[x]['created_at']\n",
    "        )\n",
    "        await self._cleanup_session(oldest_id)\n",
    "    \n",
    "    async def shutdown(self):\n",
    "        \"\"\"Shutdown all sessions.\"\"\"\n",
    "        for session_id in list(self.active_sessions.keys()):\n",
    "            await self._cleanup_session(session_id)\n",
    "        logger.info(\"Session pool shutdown complete\")\n",
    "\n",
    "# Initialize production components\n",
    "config = ProductionConfig()\n",
    "session_pool = ProductionSessionPool(config)\n",
    "print(f\"✅ Production config initialized: {config.environment}\")\n",
    "print(f\"   Max sessions: {config.max_concurrent_sessions}\")\n",
    "print(f\"   Audit logging: {config.enable_audit_logging}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Production Monitoring & Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionMonitor:\n",
    "    \"\"\"Production monitoring for LlamaIndex-AgentCore operations.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ProductionConfig):\n",
    "        self.config = config\n",
    "        self.metrics = {\n",
    "            'operations': {'total': 0, 'successful': 0, 'failed': 0, 'sensitive': 0},\n",
    "            'performance': {'avg_response_time': 0.0, 'total_data_mb': 0.0},\n",
    "            'security': {'pii_detections': 0, 'masking_ops': 0, 'violations': 0},\n",
    "            'errors': {'session_errors': 0, 'auth_errors': 0, 'processing_errors': 0}\n",
    "        }\n",
    "        self.audit_log = []\n",
    "        self.start_time = datetime.utcnow()\n",
    "    \n",
    "    def record_operation(self, operation_type: str, success: bool, duration: float, \n",
    "                        data_size_mb: float = 0.0, sensitive_data: bool = False, metadata: Dict = None):\n",
    "        \"\"\"Record operation with comprehensive metrics.\"\"\"\n",
    "        self.metrics['operations']['total'] += 1\n",
    "        \n",
    "        if success:\n",
    "            self.metrics['operations']['successful'] += 1\n",
    "        else:\n",
    "            self.metrics['operations']['failed'] += 1\n",
    "        \n",
    "        if sensitive_data:\n",
    "            self.metrics['operations']['sensitive'] += 1\n",
    "        \n",
    "        # Update performance metrics\n",
    "        total_ops = self.metrics['operations']['total']\n",
    "        current_avg = self.metrics['performance']['avg_response_time']\n",
    "        self.metrics['performance']['avg_response_time'] = (\n",
    "            (current_avg * (total_ops - 1) + duration) / total_ops\n",
    "        )\n",
    "        self.metrics['performance']['total_data_mb'] += data_size_mb\n",
    "        \n",
    "        # Create audit entry\n",
    "        if self.config.enable_audit_logging:\n",
    "            audit_entry = {\n",
    "                'timestamp': datetime.utcnow().isoformat(),\n",
    "                'operation_type': operation_type,\n",
    "                'success': success,\n",
    "                'duration_seconds': duration,\n",
    "                'data_size_mb': data_size_mb,\n",
    "                'sensitive_data': sensitive_data,\n",
    "                'metadata': metadata or {}\n",
    "            }\n",
    "            self.audit_log.append(audit_entry)\n",
    "            logger.info(f\"Operation recorded: {operation_type} - Success: {success}\")\n",
    "    \n",
    "    def record_security_event(self, event_type: str, details: Dict = None):\n",
    "        \"\"\"Record security events.\"\"\"\n",
    "        if event_type == 'pii_detection':\n",
    "            self.metrics['security']['pii_detections'] += 1\n",
    "        elif event_type == 'data_masking':\n",
    "            self.metrics['security']['masking_ops'] += 1\n",
    "        elif event_type == 'security_violation':\n",
    "            self.metrics['security']['violations'] += 1\n",
    "        \n",
    "        if self.config.enable_audit_logging:\n",
    "            security_entry = {\n",
    "                'timestamp': datetime.utcnow().isoformat(),\n",
    "                'event_type': event_type,\n",
    "                'details': details or {},\n",
    "                'severity': 'HIGH' if event_type == 'security_violation' else 'INFO'\n",
    "            }\n",
    "            self.audit_log.append(security_entry)\n",
    "            logger.warning(f\"Security event: {event_type}\")\n",
    "    \n",
    "    def get_health_status(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get system health status.\"\"\"\n",
    "        total_ops = self.metrics['operations']['total']\n",
    "        success_rate = (\n",
    "            self.metrics['operations']['successful'] / total_ops * 100\n",
    "            if total_ops > 0 else 100.0\n",
    "        )\n",
    "        \n",
    "        uptime = datetime.utcnow() - self.start_time\n",
    "        \n",
    "        return {\n",
    "            'status': 'healthy' if success_rate > 95 else 'degraded' if success_rate > 80 else 'unhealthy',\n",
    "            'uptime_seconds': uptime.total_seconds(),\n",
    "            'success_rate_percent': success_rate,\n",
    "            'total_operations': total_ops,\n",
    "            'avg_response_time': self.metrics['performance']['avg_response_time'],\n",
    "            'security_violations': self.metrics['security']['violations']\n",
    "        }\n",
    "    \n",
    "    def export_audit_log(self, filename: str = None) -> str:\n",
    "        \"\"\"Export audit log for compliance.\"\"\"\n",
    "        if not filename:\n",
    "            timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')\n",
    "            filename = f'audit_log_{timestamp}.json'\n",
    "        \n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump({\n",
    "                'export_timestamp': datetime.utcnow().isoformat(),\n",
    "                'total_entries': len(self.audit_log),\n",
    "                'audit_entries': self.audit_log\n",
    "            }, f, indent=2)\n",
    "        \n",
    "        logger.info(f\"Audit log exported to {filename}\")\n",
    "        return filename\n",
    "\n",
    "class ProductionErrorHandler:\n",
    "    \"\"\"Production error handling with circuit breaker pattern.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ProductionConfig, monitor: ProductionMonitor):\n",
    "        self.config = config\n",
    "        self.monitor = monitor\n",
    "        self.circuit_breaker_state = {}\n",
    "    \n",
    "    async def handle_with_retry(self, operation_func, operation_name: str, *args, **kwargs):\n",
    "        \"\"\"Execute operation with retry logic and monitoring.\"\"\"\n",
    "        last_error = None\n",
    "        \n",
    "        for attempt in range(self.config.max_retries + 1):\n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                result = await operation_func(*args, **kwargs)\n",
    "                duration = time.time() - start_time\n",
    "                \n",
    "                # Record successful operation\n",
    "                self.monitor.record_operation(\n",
    "                    operation_type=operation_name,\n",
    "                    success=True,\n",
    "                    duration=duration,\n",
    "                    metadata={'attempt': attempt + 1}\n",
    "                )\n",
    "                \n",
    "                return result\n",
    "                \n",
    "            except Exception as e:\n",
    "                last_error = e\n",
    "                duration = time.time() - start_time\n",
    "                \n",
    "                # Record failed operation\n",
    "                self.monitor.record_operation(\n",
    "                    operation_type=operation_name,\n",
    "                    success=False,\n",
    "                    duration=duration,\n",
    "                    metadata={'attempt': attempt + 1, 'error': str(e)}\n",
    "                )\n",
    "                \n",
    "                if attempt < self.config.max_retries:\n",
    "                    # Wait before retry with exponential backoff\n",
    "                    wait_time = 2 ** attempt\n",
    "                    logger.warning(f\"Attempt {attempt + 1} failed for {operation_name}, retrying in {wait_time}s\")\n",
    "                    await asyncio.sleep(wait_time)\n",
    "                else:\n",
    "                    logger.error(f\"All {self.config.max_retries + 1} attempts failed for {operation_name}\")\n",
    "        \n",
    "        raise last_error\n",
    "\n",
    "# Initialize monitoring and error handling\n",
    "monitor = ProductionMonitor(config)\n",
    "error_handler = ProductionErrorHandler(config, monitor)\n",
    "print(\"✅ Production monitoring initialized\")\n",
    "print(f\"   Audit logging: {config.enable_audit_logging}\")\n",
    "print(f\"   Max retries: {config.max_retries}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Production RAG Pipeline with Security"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionLlamaIndexRAG:\n",
    "    \"\"\"Production-ready LlamaIndex RAG with AgentCore Browser Tool.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ProductionConfig, monitor: ProductionMonitor,\n",
    "                 error_handler: ProductionErrorHandler, session_pool: ProductionSessionPool):\n",
    "        self.config = config\n",
    "        self.monitor = monitor\n",
    "        self.error_handler = error_handler\n",
    "        self.session_pool = session_pool\n",
    "        \n",
    "        # Initialize LlamaIndex components\n",
    "        self.llm = Bedrock(\n",
    "            model=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "            region_name=config.region,\n",
    "            max_tokens=config.max_tokens\n",
    "        )\n",
    "        \n",
    "        self.embed_model = BedrockEmbedding(\n",
    "            model=\"amazon.titan-embed-text-v1\",\n",
    "            region_name=config.region\n",
    "        )\n",
    "        \n",
    "        Settings.llm = self.llm\n",
    "        Settings.embed_model = self.embed_model\n",
    "        Settings.chunk_size = config.chunk_size\n",
    "        \n",
    "        # Initialize secure components\n",
    "        self.browser_loader = AgentCoreBrowserLoader(region=config.region)\n",
    "        self.data_handler = SensitiveDataHandler()\n",
    "        self.secure_rag = SecureRAGPipeline()\n",
    "        \n",
    "        self.index = None\n",
    "        self.query_engine = None\n",
    "    \n",
    "    async def ingest_secure_web_data(self, urls: List[str], \n",
    "                                   auth_configs: Dict[str, Dict] = None) -> Dict[str, Any]:\n",
    "        \"\"\"Ingest web data securely with monitoring.\"\"\"\n",
    "        async def _ingest_operation():\n",
    "            session = await self.session_pool.get_session()\n",
    "            documents = []\n",
    "            stats = {\n",
    "                'total_urls': len(urls),\n",
    "                'successful': 0,\n",
    "                'failed': 0,\n",
    "                'sensitive_docs': 0,\n",
    "                'total_data_mb': 0.0\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                for url in urls:\n",
    "                    try:\n",
    "                        logger.info(f\"Processing URL: {url}\")\n",
    "                        \n",
    "                        # Get auth config if provided\n",
    "                        auth_config = auth_configs.get(url) if auth_configs else None\n",
    "                        \n",
    "                        # Load web content securely\n",
    "                        web_documents = await self.browser_loader.load_with_session(\n",
    "                            session, url, auth_config\n",
    "                        )\n",
    "                        \n",
    "                        # Process documents for sensitive data\n",
    "                        for doc in web_documents:\n",
    "                            # Detect sensitive data\n",
    "                            sensitivity_analysis = self.data_handler.analyze_sensitivity(doc.text)\n",
    "                            \n",
    "                            if sensitivity_analysis['has_sensitive_data']:\n",
    "                                stats['sensitive_docs'] += 1\n",
    "                                self.monitor.record_security_event('pii_detection', {\n",
    "                                    'url': url,\n",
    "                                    'pii_types': sensitivity_analysis['pii_types']\n",
    "                                })\n",
    "                                \n",
    "                                # Apply data masking\n",
    "                                masked_doc = self.data_handler.mask_sensitive_data(doc)\n",
    "                                documents.append(masked_doc)\n",
    "                                \n",
    "                                self.monitor.record_security_event('data_masking', {\n",
    "                                    'url': url,\n",
    "                                    'masking_applied': True\n",
    "                                })\n",
    "                            else:\n",
    "                                documents.append(doc)\n",
    "                            \n",
    "                            # Update data size\n",
    "                            doc_size_mb = len(doc.text.encode('utf-8')) / (1024 * 1024)\n",
    "                            stats['total_data_mb'] += doc_size_mb\n",
    "                        \n",
    "                        stats['successful'] += 1\n",
    "                        logger.info(f\"Successfully processed {len(web_documents)} documents from {url}\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        stats['failed'] += 1\n",
    "                        logger.error(f\"Failed to process URL {url}: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                # Create secure vector index\n",
    "                if documents:\n",
    "                    self.index = await self._create_secure_index(documents)\n",
    "                    self.query_engine = self.index.as_query_engine(\n",
    "                        response_mode=\"compact\",\n",
    "                        streaming=False\n",
    "                    )\n",
    "                    logger.info(f\"Created secure index with {len(documents)} documents\")\n",
    "                \n",
    "                return {\n",
    "                    'success': True,\n",
    "                    'documents_processed': len(documents),\n",
    "                    'statistics': stats,\n",
    "                    'index_created': self.index is not None\n",
    "                }\n",
    "                \n",
    "            finally:\n",
    "                if session:\n",
    "                    await session.close()\n",
    "        \n",
    "        return await self.error_handler.handle_with_retry(\n",
    "            _ingest_operation, \"secure_web_ingestion\"\n",
    "        )\n",
    "    \n",
    "    async def _create_secure_index(self, documents: List[Document]) -> VectorStoreIndex:\n",
    "        \"\"\"Create secure vector index with monitoring.\"\"\"\n",
    "        try:\n",
    "            # Parse documents with security-aware chunking\n",
    "            parser = SentenceSplitter(\n",
    "                chunk_size=self.config.chunk_size,\n",
    "                chunk_overlap=20\n",
    "            )\n",
    "            \n",
    "            nodes = parser.get_nodes_from_documents(documents)\n",
    "            index = VectorStoreIndex(nodes)\n",
    "            \n",
    "            logger.info(f\"Created secure vector index with {len(nodes)} nodes\")\n",
    "            return index\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to create secure index: {e}\")\n",
    "            raise\n",
    "    \n",
    "    async def query_with_security(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Execute query with security and monitoring.\"\"\"\n",
    "        async def _query_operation():\n",
    "            if not self.query_engine:\n",
    "                raise ValueError(\"No index available. Please ingest data first.\")\n",
    "            \n",
    "            # Sanitize query\n",
    "            sanitized_query = self.data_handler.sanitize_query(query)\n",
    "            \n",
    "            if sanitized_query != query:\n",
    "                self.monitor.record_security_event('query_sanitization', {\n",
    "                    'original_length': len(query),\n",
    "                    'sanitized_length': len(sanitized_query)\n",
    "                })\n",
    "            \n",
    "            # Execute query\n",
    "            start_time = time.time()\n",
    "            response = self.query_engine.query(sanitized_query)\n",
    "            query_duration = time.time() - start_time\n",
    "            \n",
    "            # Sanitize response\n",
    "            sanitized_response = self.data_handler.sanitize_response(str(response))\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'response': sanitized_response,\n",
    "                'query_duration': query_duration,\n",
    "                'source_nodes': len(response.source_nodes) if hasattr(response, 'source_nodes') else 0,\n",
    "                'sanitization_applied': sanitized_response != str(response)\n",
    "            }\n",
    "        \n",
    "        return await self.error_handler.handle_with_retry(\n",
    "            _query_operation, \"secure_query_execution\"\n",
    "        )\n",
    "    \n",
    "    def get_system_health(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get comprehensive system health.\"\"\"\n",
    "        return {\n",
    "            'monitor_health': self.monitor.get_health_status(),\n",
    "            'session_pool_metrics': self.session_pool.metrics,\n",
    "            'index_status': {\n",
    "                'index_created': self.index is not None,\n",
    "                'query_engine_ready': self.query_engine is not None\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    async def shutdown(self):\n",
    "        \"\"\"Graceful shutdown.\"\"\"\n",
    "        logger.info(\"Shutting down production RAG system...\")\n",
    "        \n",
    "        # Export audit log\n",
    "        audit_file = self.monitor.export_audit_log()\n",
    "        logger.info(f\"Audit log exported to: {audit_file}\")\n",
    "        \n",
    "        # Shutdown session pool\n",
    "        await self.session_pool.shutdown()\n",
    "        \n",
    "        logger.info(\"Production RAG system shutdown complete\")\n",
    "\n",
    "# Initialize production RAG system\n",
    "production_rag = ProductionLlamaIndexRAG(config, monitor, error_handler, session_pool)\n",
    "print(\"✅ Production RAG system initialized\")\n",
    "print(f\"   LLM: {production_rag.llm.model}\")\n",
    "print(f\"   Chunk size: {config.chunk_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Production Demonstration & Compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def demonstrate_production_patterns():\n",
    "    \"\"\"Demonstrate production patterns with monitoring.\"\"\"\n",
    "    \n",
    "    print(\"🚀 Production LlamaIndex-AgentCore Demonstration\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    # Production URLs with different sensitivity levels\n",
    "    production_urls = [\n",
    "        \"https://httpbin.org/forms/post\",  # Form with potential PII\n",
    "        \"https://httpbin.org/basic-auth/user/pass\",  # Authenticated content\n",
    "        \"https://httpbin.org/json\",  # JSON data\n",
    "        \"https://httpbin.org/html\"   # HTML content\n",
    "    ]\n",
    "    \n",
    "    auth_configs = {\n",
    "        \"https://httpbin.org/basic-auth/user/pass\": {\n",
    "            \"type\": \"basic\",\n",
    "            \"username\": \"user\",\n",
    "            \"password\": \"pass\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # 1. Secure data ingestion\n",
    "        print(\"\\n📥 Phase 1: Secure Data Ingestion\")\n",
    "        print(\"-\" * 35)\n",
    "        \n",
    "        ingestion_result = await production_rag.ingest_secure_web_data(\n",
    "            urls=production_urls,\n",
    "            auth_configs=auth_configs\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ Ingestion completed:\")\n",
    "        print(f\"   Documents processed: {ingestion_result['documents_processed']}\")\n",
    "        print(f\"   Sensitive documents: {ingestion_result['statistics']['sensitive_docs']}\")\n",
    "        print(f\"   Data size: {ingestion_result['statistics']['total_data_mb']:.2f} MB\")\n",
    "        print(f\"   Success rate: {ingestion_result['statistics']['successful']}/{ingestion_result['statistics']['total_urls']}\")\n",
    "        \n",
    "        # 2. Secure querying\n",
    "        print(\"\\n🔍 Phase 2: Secure Query Execution\")\n",
    "        print(\"-\" * 35)\n",
    "        \n",
    "        test_queries = [\n",
    "            \"What information is available in the processed documents?\",\n",
    "            \"Are there any forms or authentication methods?\",\n",
    "            \"Summarize the JSON data structure found\"\n",
    "        ]\n",
    "        \n",
    "        for i, query in enumerate(test_queries, 1):\n",
    "            print(f\"\\nQuery {i}: {query}\")\n",
    "            \n",
    "            query_result = await production_rag.query_with_security(query)\n",
    "            \n",
    "            print(f\"✅ Response ({query_result['query_duration']:.2f}s):\")\n",
    "            print(f\"   {query_result['response'][:150]}...\")\n",
    "            print(f\"   Source nodes: {query_result['source_nodes']}\")\n",
    "            print(f\"   Sanitization: {query_result['sanitization_applied']}\")\n",
    "        \n",
    "        # 3. System health monitoring\n",
    "        print(\"\\n📊 Phase 3: System Health & Metrics\")\n",
    "        print(\"-\" * 35)\n",
    "        \n",
    "        health_status = production_rag.get_system_health()\n",
    "        \n",
    "        print(f\"System Status: {health_status['monitor_health']['status'].upper()}\")\n",
    "        print(f\"Success Rate: {health_status['monitor_health']['success_rate_percent']:.1f}%\")\n",
    "        print(f\"Total Operations: {health_status['monitor_health']['total_operations']}\")\n",
    "        print(f\"Avg Response Time: {health_status['monitor_health']['avg_response_time']:.2f}s\")\n",
    "        print(f\"Security Violations: {health_status['monitor_health']['security_violations']}\")\n",
    "        \n",
    "        # 4. Compliance reporting\n",
    "        print(\"\\n📋 Phase 4: Compliance Reporting\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Generate compliance metrics\n",
    "        compliance_metrics = {\n",
    "            'audit_log_entries': len(monitor.audit_log),\n",
    "            'sensitive_operations': monitor.metrics['operations']['sensitive'],\n",
    "            'pii_detections': monitor.metrics['security']['pii_detections'],\n",
    "            'masking_operations': monitor.metrics['security']['masking_ops'],\n",
    "            'data_protection_enabled': config.enable_pii_detection,\n",
    "            'audit_logging_enabled': config.enable_audit_logging\n",
    "        }\n",
    "        \n",
    "        print(f\"Audit Log Entries: {compliance_metrics['audit_log_entries']}\")\n",
    "        print(f\"Sensitive Operations: {compliance_metrics['sensitive_operations']}\")\n",
    "        print(f\"PII Detections: {compliance_metrics['pii_detections']}\")\n",
    "        print(f\"Masking Operations: {compliance_metrics['masking_operations']}\")\n",
    "        print(f\"Data Protection: {'✅ Enabled' if compliance_metrics['data_protection_enabled'] else '❌ Disabled'}\")\n",
    "        print(f\"Audit Logging: {'✅ Enabled' if compliance_metrics['audit_logging_enabled'] else '❌ Disabled'}\")\n",
    "        \n",
    "        # Export audit log\n",
    "        audit_filename = monitor.export_audit_log()\n",
    "        print(f\"\\n📄 Audit log exported: {audit_filename}\")\n",
    "        \n",
    "        print(\"\\n✅ Production demonstration completed successfully!\")\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            'ingestion_result': ingestion_result,\n",
    "            'health_status': health_status,\n",
    "            'compliance_metrics': compliance_metrics,\n",
    "            'audit_file': audit_filename\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Demonstration failed: {e}\")\n",
    "        logger.error(f\"Production demonstration failed: {e}\")\n",
    "        return {'success': False, 'error': str(e)}\n",
    "\n",
    "# Production best practices summary\n",
    "def display_production_best_practices():\n",
    "    \"\"\"Display production best practices.\"\"\"\n",
    "    \n",
    "    best_practices = {\n",
    "        \"🏗️ Architecture\": [\n",
    "            \"Use session pooling for efficient resource management\",\n",
    "            \"Implement circuit breakers for resilient error handling\",\n",
    "            \"Design for horizontal scaling across regions\",\n",
    "            \"Separate sensitive and non-sensitive data pipelines\"\n",
    "        ],\n",
    "        \"🔒 Security\": [\n",
    "            \"Always enable PII detection and masking\",\n",
    "            \"Use AgentCore's containerized isolation\",\n",
    "            \"Implement comprehensive audit logging\",\n",
    "            \"Never expose sensitive data in error messages\",\n",
    "            \"Encrypt data at rest and in transit\"\n",
    "        ],\n",
    "        \"📊 Monitoring\": [\n",
    "            \"Monitor session pool utilization\",\n",
    "            \"Set up alerts for security violations\",\n",
    "            \"Track PII detection and masking rates\",\n",
    "            \"Monitor authentication success rates\",\n",
    "            \"Implement real-time dashboards\"\n",
    "        ],\n",
    "        \"⚠️ Error Handling\": [\n",
    "            \"Implement retry logic with exponential backoff\",\n",
    "            \"Use circuit breakers to prevent cascade failures\",\n",
    "            \"Handle session timeouts gracefully\",\n",
    "            \"Sanitize all error messages\",\n",
    "            \"Implement fallback strategies\"\n",
    "        ],\n",
    "        \"📋 Compliance\": [\n",
    "            \"Maintain comprehensive audit trails\",\n",
    "            \"Implement data retention policies\",\n",
    "            \"Regular compliance reporting\",\n",
    "            \"Document data flows and processing\",\n",
    "            \"Conduct security assessments\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"\\n📚 Production Best Practices\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    for category, practices in best_practices.items():\n",
    "        print(f\"\\n{category}\")\n",
    "        for i, practice in enumerate(practices, 1):\n",
    "            print(f\"  {i}. {practice}\")\n",
    "\n",
    "# Run demonstration\n",
    "print(\"Starting production demonstration...\")\n",
    "demo_result = await demonstrate_production_patterns()\n",
    "\n",
    "if demo_result['success']:\n",
    "    print(\"\\n🎉 Production patterns demonstration completed!\")\n",
    "    display_production_best_practices()\n",
    "else:\n",
    "    print(f\"\\n⚠️ Issues encountered: {demo_result.get('error', 'Unknown')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cleanup & Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def production_cleanup():\n",
    "    \"\"\"Production cleanup and final reporting.\"\"\"\n",
    "    \n",
    "    print(\"\\n🧹 Production Cleanup\")\n",
    "    print(\"=\" * 25)\n",
    "    \n",
    "    try:\n",
    "        # Final metrics\n",
    "        final_health = production_rag.get_system_health()\n",
    "        \n",
    "        print(\"\\n📈 Final System Metrics:\")\n",
    "        print(f\"   Total Operations: {final_health['monitor_health']['total_operations']}\")\n",
    "        print(f\"   Success Rate: {final_health['monitor_health']['success_rate_percent']:.1f}%\")\n",
    "        print(f\"   Avg Response Time: {final_health['monitor_health']['avg_response_time']:.2f}s\")\n",
    "        print(f\"   Security Violations: {final_health['monitor_health']['security_violations']}\")\n",
    "        \n",
    "        # Export final audit log\n",
    "        final_audit = monitor.export_audit_log('final_audit_log.json')\n",
    "        print(f\"\\n📄 Final audit log: {final_audit}\")\n",
    "        \n",
    "        # Shutdown systems\n",
    "        await production_rag.shutdown()\n",
    "        \n",
    "        print(\"\\n✅ Production cleanup completed successfully\")\n",
    "        \n",
    "        return {'cleanup_success': True}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Cleanup error: {e}\")\n",
    "        return {'cleanup_success': False, 'error': str(e)}\n",
    "\n",
    "# Perform cleanup\n",
    "cleanup_result = await production_cleanup()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📋 PRODUCTION TUTORIAL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n✅ What We Accomplished:\")\n",
    "print(\"   • Scalable session pooling with auto-cleanup\")\n",
    "print(\"   • Comprehensive monitoring and observability\")\n",
    "print(\"   • Robust error handling with circuit breakers\")\n",
    "print(\"   • Security-first design with PII protection\")\n",
    "print(\"   • Compliance-ready audit logging\")\n",
    "print(\"   • Production deployment patterns\")\n",
    "\n",
    "print(\"\\n🚀 Next Steps:\")\n",
    "print(\"   1. Deploy using these production patterns\")\n",
    "print(\"   2. Customize configuration for your requirements\")\n",
    "print(\"   3. Set up monitoring dashboards and alerts\")\n",
    "print(\"   4. Conduct security reviews and testing\")\n",
    "print(\"   5. Validate compliance with regulations\")\n",
    "\n",
    "print(\"\\n💡 Key Takeaways:\")\n",
    "print(\"   • Security is paramount - always use PII detection\")\n",
    "print(\"   • Monitor everything for proactive issue resolution\")\n",
    "print(\"   • Plan for failure with robust error handling\")\n",
    "print(\"   • Build compliance features from the start\")\n",
    "print(\"   • Use session pooling for efficient scaling\")\n",
    "\n",
    "print(\"\\n🎯 This completes the production LlamaIndex-AgentCore tutorial series!\")\n",
    "print(\"   You now have enterprise-ready patterns for secure, scalable AI applications.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}